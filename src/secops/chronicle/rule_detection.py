# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
"""Detection functionality for Chronicle rules."""

from typing import Dict, Any, Optional
from secops.exceptions import APIError


def list_detections(
    client,
    rule_id: str,
    alert_state: Optional[str] = None,
    page_size: Optional[int] = None,
    page_token: Optional[str] = None
) -> Dict[str, Any]:
    """List detections for a rule.

    Args:
        client: ChronicleClient instance
        rule_id: Unique ID of the rule to list detections for. Options are:
            - {rule_id} (latest version)
            - {rule_id}@v_<seconds>_<nanoseconds> (specific version)
            - {rule_id}@- (all versions)
        alert_state: If provided, filter by alert state. Valid values are:
            - "UNSPECIFIED"
            - "NOT_ALERTING"
            - "ALERTING"
        page_size: If provided, maximum number of detections to return
        page_token: If provided, continuation token for pagination

    Returns:
        Dictionary containing detection information

    Raises:
        APIError: If the API request fails
        ValueError: If an invalid alert_state is provided
    """
    url = f"{client.base_url}/{client.instance_id}/legacy:legacySearchDetections"

    # Define valid alert states
    valid_alert_states = ["UNSPECIFIED", "NOT_ALERTING", "ALERTING"]

    # Build request parameters
    params = {
        "rule_id": rule_id,
    }

    if alert_state:
        if alert_state not in valid_alert_states:
            raise ValueError(f"alert_state must be one of {valid_alert_states}, got {alert_state}")
        params["alertState"] = alert_state

    if page_size:
        params["pageSize"] = page_size

    if page_token:
        params["pageToken"] = page_token

    response = client.session.get(url, params=params)

    if response.status_code != 200:
        raise APIError(f"Failed to list detections: {response.text}")

    return response.json()

# --- Added Functions Start Here ---

def get_detection(
    client,
    detection_id: str
) -> Dict[str, Any]:
    """Gets a single detection by its ID.

    Args:
        client: ChronicleClient instance
        detection_id: The unique ID of the detection to retrieve.

    Returns:
        Dictionary containing the detection details.

    Raises:
        APIError: If the API request fails.
    """
    url = f"{client.base_url}/{client.instance_id}/legacy:legacyGetDetection"
    params = {"detection_id": detection_id}
    response = client.session.get(url, params=params)

    if response.status_code != 200:
        raise APIError(f"Failed to get detection {detection_id}: {response.text}")

    return response.json()


def search_curated_detections(
    client,
    rule_id: str,
    start_time: Optional[str] = None,
    end_time: Optional[str] = None,
    page_size: Optional[int] = None,
    page_token: Optional[str] = None
) -> Dict[str, Any]:
    """Lists detections specifically generated by a curated rule set.

    Args:
        client: ChronicleClient instance
        rule_id: Unique ID of the curated rule to list detections for.
        start_time: Optional start time for the query (RFC3339 format).
        end_time: Optional end time for the query (RFC3339 format).
        page_size: If provided, maximum number of detections to return.
        page_token: If provided, continuation token for pagination.

    Returns:
        Dictionary containing curated detection information.

    Raises:
        APIError: If the API request fails.
    """
    url = f"{client.base_url}/{client.instance_id}/legacy:legacySearchCuratedDetections"
    params = {"rule_id": rule_id}

    if start_time:
        params["start_time"] = start_time
    if end_time:
        params["end_time"] = end_time
    if page_size:
        params["page_size"] = page_size
    if page_token:
        params["page_token"] = page_token

    response = client.session.get(url, params=params)

    if response.status_code != 200:
        raise APIError(f"Failed to search curated detections for rule {rule_id}: {response.text}")

    return response.json()


def count_all_curated_rule_set_detections(
    client,
    start_time: Optional[str] = None,
    end_time: Optional[str] = None,
    filter_str: Optional[str] = None
) -> Dict[str, Any]:
    """Counts detections across all enabled curated rule sets within the instance.

    Args:
        client: ChronicleClient instance
        start_time: Optional start time for the count (RFC3339 format).
        end_time: Optional end time for the count (RFC3339 format).
        filter_str: Optional filter string (e.g., based on rule set ID).

    Returns:
        Dictionary containing the detection counts.

    Raises:
        APIError: If the API request fails.
    """
    url = f"{client.base_url}/{client.instance_id}:countAllCuratedRuleSetDetections"
    payload = {}
    if start_time:
        payload["startTime"] = start_time
    if end_time:
        payload["endTime"] = end_time
    if filter_str:
        payload["filter"] = filter_str

    response = client.session.post(url, json=payload)

    if response.status_code != 200:
        raise APIError(f"Failed to count all curated rule set detections: {response.text}")

    return response.json()


def count_curated_rule_set_detections(
    client,
    category_id: str,
    rule_set_id: str,
    start_time: Optional[str] = None,
    end_time: Optional[str] = None,
    filter_str: Optional[str] = None
) -> Dict[str, Any]:
    """Counts detections generated by a specific curated rule set.

    Args:
        client: ChronicleClient instance
        category_id: The ID of the curated rule set category.
        rule_set_id: The ID of the specific curated rule set.
        start_time: Optional start time for the count (RFC3339 format).
        end_time: Optional end time for the count (RFC3339 format).
        filter_str: Optional filter string.

    Returns:
        Dictionary containing the detection counts for the specific rule set.

    Raises:
        APIError: If the API request fails.
    """
    # Construct the full resource name for the rule set
    # Assuming client.instance_id format is projects/X/locations/Y/instances/Z
    rule_set_name = f"{client.instance_id}/curatedRuleSetCategories/{category_id}/curatedRuleSets/{rule_set_id}"
    url = f"{client.base_url}/{rule_set_name}:countCuratedRuleSetDetections"

    payload = {}
    if start_time:
        payload["startTime"] = start_time
    if end_time:
        payload["endTime"] = end_time
    if filter_str:
        payload["filter"] = filter_str

    response = client.session.post(url, json=payload)

    if response.status_code != 200:
        raise APIError(f"Failed to count detections for curated rule set {rule_set_id}: {response.text}")

    return response.json()


def search_detection_events(
    client,
    detection_id: str,
    page_size: Optional[int] = None,
    page_token: Optional[str] = None
) -> Dict[str, Any]:
    """Retrieves the underlying UDM events that contributed to a specific detection.

    Args:
        client: ChronicleClient instance
        detection_id: The unique ID of the detection.
        page_size: If provided, maximum number of events to return.
        page_token: If provided, continuation token for pagination.

    Returns:
        Dictionary containing the UDM events associated with the detection.

    Raises:
        APIError: If the API request fails.
    """
    url = f"{client.base_url}/{client.instance_id}/legacy:legacySearchRuleDetectionEvents"
    params = {"detection_id": detection_id}

    if page_size:
        params["page_size"] = page_size
    if page_token:
        params["page_token"] = page_token

    response = client.session.get(url, params=params)

    if response.status_code != 200:
        raise APIError(f"Failed to search detection events for {detection_id}: {response.text}")

    return response.json()


def search_detection_count_buckets(
    client,
    rule_id: str,
    start_time: Optional[str] = None,
    end_time: Optional[str] = None,
    bucket_duration: Optional[str] = None # e.g., "3600s" for hourly
) -> Dict[str, Any]:
    """Lists detection counts aggregated into time buckets for a specific rule.

    Args:
        client: ChronicleClient instance
        rule_id: Unique ID of the rule.
        start_time: Optional start time for the query (RFC3339 format).
        end_time: Optional end time for the query (RFC3339 format).
        bucket_duration: Optional duration string for aggregation buckets (e.g., "60s", "3600s").

    Returns:
        Dictionary containing detection count buckets.

    Raises:
        APIError: If the API request fails.
    """
    url = f"{client.base_url}/{client.instance_id}/legacy:legacySearchRuleDetectionCountBuckets"
    params = {"rule_id": rule_id}

    if start_time:
        params["start_time"] = start_time
    if end_time:
        params["end_time"] = end_time
    if bucket_duration:
        params["bucket_duration"] = bucket_duration

    response = client.session.get(url, params=params)

    if response.status_code != 200:
        raise APIError(f"Failed to search detection count buckets for rule {rule_id}: {response.text}")

    return response.json()


def search_rule_results(
    client,
    rule_id: str,
    start_time: Optional[str] = None,
    end_time: Optional[str] = None,
    page_size: Optional[int] = None,
    page_token: Optional[str] = None
) -> Dict[str, Any]:
    """Lists aggregated results for a Rules Engine rule.

    Args:
        client: ChronicleClient instance
        rule_id: Unique ID of the rule.
        start_time: Optional start time for the query (RFC3339 format).
        end_time: Optional end time for the query (RFC3339 format).
        page_size: If provided, maximum number of results to return.
        page_token: If provided, continuation token for pagination.

    Returns:
        Dictionary containing aggregated rule results.

    Raises:
        APIError: If the API request fails.
    """
    url = f"{client.base_url}/{client.instance_id}/legacy:legacySearchRuleResults"
    params = {"rule_id": rule_id}

    if start_time:
        params["start_time"] = start_time
    if end_time:
        params["end_time"] = end_time
    if page_size:
        params["page_size"] = page_size
    if page_token:
        params["page_token"] = page_token

    response = client.session.get(url, params=params)

    if response.status_code != 200:
        raise APIError(f"Failed to search rule results for rule {rule_id}: {response.text}")

    return response.json()

# --- Added Functions End Here ---

def list_errors(
    client,
    rule_id: str
) -> Dict[str, Any]:
    """List execution errors for a rule.

    Args:
        client: ChronicleClient instance
        rule_id: Unique ID of the rule to list errors for. Options are:
            - {rule_id} (latest version)
            - {rule_id}@v_<seconds>_<nanoseconds> (specific version)
            - {rule_id}@- (all versions)

    Returns:
        Dictionary containing rule execution errors

    Raises:
        APIError: If the API request fails
    """
    url = f"{client.base_url}/{client.instance_id}/ruleExecutionErrors"

    # Create the filter for the specific rule
    # Note: The API expects the full resource name, including the instance ID.
    # Assuming client.instance_id format is projects/X/locations/Y/instances/Z
    rule_resource_name = f"{client.instance_id}/rules/{rule_id}"
    rule_filter = (
        f'rule = "{rule_resource_name}"'
    )

    params = {
        "filter": rule_filter,
    }

    response = client.session.get(url, params=params)

    if response.status_code != 200:
        raise APIError(f"Failed to list rule errors: {response.text}")

    return response.json()
